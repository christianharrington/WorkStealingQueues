%!TEX root = ../Work-stealing Queues.tex
\section{Performance Analysis}
\label{sec:performance_analysis}
\subsection{Chase-Lev vs ABP}
When comparing the performance of the Chase-Lev and ABP implementations we see that Chase-Lev is faster at quick sort and XML serialization. On the surface it might seem odd that Chase-Lev should outperform ABP as Chase-Lev also has to maintain the circular array. However, as Chase-Lev does not have to deal with the ABA problem this better performance could be due to a lot of failed CAS operations in ABP\@. In general Chase-Lev cannot be expected to perform better then ABP\@. We can also see that Chase-Lev tends to be slower than ABP on cases with low cost tasks (Spanning-Tree and Raw) and speeds up as tasks become more work intensive. If more time is needed by each task the relative time spend on queue operation lowers and thus the increased overhead of Chase-Lev has less of an effect on the overall performance.

Another advantage of Chase-Lev is that it does not need to know size of the queue before hand. This allows for more memory efficiency and makes it easier for the user. This means that Chase-Lev in general is a good choice for cases where the number of subtasks created by each task is hard to predict precisely, and especially for cases with more intensive individual tasks.

\subsection{Quick Sort scaling}
The performance of our quick sort case does not scale well. The performance increase from eight to sixteen workers is negligible, and past sixteen the time taken actually increases. There are a few factors that could be the source of this. Firstly, as the first worker has to split the entire list in two, and then only spawns work for one new worker, there is a large period of time where most of the workers have nothing to do. This is not a problem if each worker have their own core, but when there are more workers than cores (here past sixteen workers) it could affect performance. Maintaining the remaining workers sitting in a steal loop waiting for work to be available, could cause more overhead than the performance gained from more threads when there is work to do. Another reason could be that quick sort relies on a large amount of memory accesses. If this is the bottleneck rather than the operations on the CPU it could explain why it does not scale well. This however does not explain the extra time it takes with more than sixteen cores.

\subsection{Performance of Idempotent Queues}
Looking at the idempotent queues they are very slow in the raw case. At first this does not seem right as one of the advantages of the idempotent queues should be faster queue operations which is exactly what raw tests. The reason for this bad performance is that there is no synchronization of information on what work is done and what needs to be done. If two threads grab the same task, they both spawn the children of that task, which will be added to their queues. This means that if two workers do the same task it is not only the task itself that has to be executed twice, but also all the children of that task.

This is backed by the fact that the duplicating queue is a lot faster at raw than the other idempotent queues. This is because the duplicating queue only duplicates work when exactly one thief steals a task at the same time as the owner. In the cases of the other idempotent queues it can happen to any number of thieves at the same time, and is therefore a lot more frequently occurring. With less work duplication the duplicating queue performs a lot better in the raw case.
% Duplicating Queue er langt bedre end de andre itempotent queues i nogle tilf√¶lde

% Hyper Threading vs Thread Overhead
% Shrinking Chase-Lev er hurtigere end Chase-Lev
