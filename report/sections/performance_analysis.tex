%!TEX root = ../Work-stealing Queues.tex
\section{Performance Analysis}
This section analyses the results of our benchmarks. We focus on some interesting observations, and discuss the cause behind the results we are seeing.
\label{sec:performance_analysis}
\todo{Write why ABP being so good is not surprising. Write about how complicated the different queues are.}
\subsection{Chase-Lev vs. ABP}
When comparing the performance of the Chase-Lev and ABP implementations in Figure \ref{fig:32nonidem}, we see that Chase-Lev is faster at quick sort and XML serialization. On the surface it might seem odd that Chase-Lev should outperform ABP as Chase-Lev also has to maintain the circular array. However, as Chase-Lev does not have to deal with the ABA problem this better performance could be due to a lot of failed CAS operations in ABP\@. In general, Chase-Lev therefore cannot be expected to perform better than ABP\@. We can also see that Chase-Lev tends to be slower than ABP on cases with low cost tasks (Spanning tree and Raw) and speeds up as tasks become more work intensive. If more time is needed for each task, the relative time spend on queue operations lowers and thus the increased overhead of Chase-Lev has less of an effect on the overall performance.

\begin{figure}
\begin{tikzpicture}
\begin{axis}[title=Results for 32 threads,  
  ylabel={Relative speedup},
  symbolic x coords={ABP, Chase-Lev, Chase-Lev (Shrinking)},
  xtick=data,
  x tick label style={rotate=315,anchor=west},
  legend style={at={(1.17,1)}, anchor=north,legend columns=1},
  legend cell align=left,
  ybar, bar width=8,
  height=150,
  width=300]
\addplot coordinates { % Quick sort
(ABP,1) (Chase-Lev, 1.044061) (Chase-Lev (Shrinking), 1.173693)
};
\addplot coordinates { % Spanning tree
(ABP,1) (Chase-Lev, 1.013258) (Chase-Lev (Shrinking), 1.056889)
};
\addplot coordinates { % XML
(ABP,1) (Chase-Lev, 1.188274) (Chase-Lev (Shrinking), 1.165794)
};
\addplot coordinates { % Raw
(ABP,1) (Chase-Lev, 0.753401) (Chase-Lev (Shrinking), 0.869602)
};
\legend{Quick sort, Spanning tree, XML, Raw}
\end{axis}
\end{tikzpicture}
\caption{Results for 32 threads with non-idempotent queues.}
\label{fig:32nonidem}
\end{figure}

Another advantage of Chase-Lev queue is that it does not need to know the size of the queue beforehand. This allows for more memory efficiency and makes it easier for the user. This means that Chase-Lev in general is a good choice for cases where the number of subtasks created by each task is hard to predict precisely, and especially for cases with more intensive individual tasks.

We have also made a shrinking version of Chase-Lev which has yielded some interesting results. Since this queue requires more overhead to not only expand the queue, but to also shrink it, we expected it to perform worse than both ABP and the standard Chase-Lev queue. However, it has performed just as well as the two others and even outperformed them in certain cases. The reason for this could be garbage collection. Since ABP has to have a queue at the size of the worst case scenario, most of the time only very little of that will actually be used. In contrast, the Chase-Lev shrinking queue is only as big as needed, and the leftovers are garbage collected during execution. This means that there are many more items for the garbage collector to keep track of in the ABP queue which might affect the performance when compared to the Chase-Lev queues.

\subsection{Quick Sort and XML Serialization Scaling}
As can be seen from Figure~\ref{fig:qsscaling}, the Quick Sort case does not scale well past 16 threads. The XML Serialization case also scales poorly past 16 cores (see Appendix~\ref{app:results}). While we have not been able to pinpoint the exact cause of this, we believe it to be caused by the two CPUs of the test system.
CAS operations can incur significant overhead when dealing with multiple cores not on the same die\,\cite[p. 19--20]{Dice06whatreally}, but this should affect all our use cases equally. One of the things that sets the Quick Sort and XML Serialization apart from the other cases is that they are much more memory intensive. Keeping all this data synchronized between the two CPUs might be the cause of the slowdown past 16 cores.

\begin{figure}
\begin{tikzpicture}
\begin{axis}[
  title={Quick sort},
  xlabel={No. of threads},
  ylabel={Time (milliseconds)},
  xtick={8,16,32,48},
  legend style={at={(1.34,1)}, anchor=north,legend columns=1},
  legend cell align=left
  ]
\addplot+[sharp plot] coordinates % ABP
{(8,262.86) (16,243.2) (32,423.68) (48, 400.28)};
\addplot+[sharp plot] coordinates % Chase-Lev
{(8,252.67) (16,228.27) (32,405.8) (48, 351.26)};
\addplot+[sharp plot] coordinates % Chase-Lev (Shrinking
{(8,251.47) (16,224.93) (32,360.98) (48, 379.75)};
\legend{ABP, Chase-Lev, Chase-Lev (Shrinking)}
\end{axis}
\end{tikzpicture}
\caption{Quick sort scaling.}
\label{fig:qsscaling}
\end{figure}

\subsection{Performance of Idempotent Queues}
Looking at Figure \ref{fig:idemraw}, the idempotent queues are very slow in the Raw case. At first this does not seem right, as one of the advantages of the idempotent queues should be faster queue operations, which is exactly what Raw tests. The reason for this bad performance can be that there is no synchronization of information on what work is done and what needs to be done. If two threads receive the same task from a queue, they both spawn the children of that task, which will both be added to their respective queues. This means that if two workers perform the same task, not only the task itself has to be executed twice, but also all the children of that task.

\begin{figure}
\begin{tikzpicture}
\begin{axis}[title=Results for 32 threads,  
  ylabel={Relative speedup},
  symbolic x coords={ABP, Idempotent (LIFO), Idempotent (FIFO),
                     Idempotent (Double-ended), Duplicating},
  xtick=data,
  x tick label style={rotate=315,anchor=west},
  legend style={at={(1.17,1)}, anchor=north,legend columns=1},
  legend cell align=left,
  ybar, bar width=10,
  height=150,
  width=300]
\addplot coordinates { % Raw
(ABP,1) (Idempotent (LIFO), 0.210492)
(Idempotent (FIFO), 0.171293) (Idempotent (Double-ended), 0.118589) (Duplicating, 0.708532)
};
\legend{Raw}
\end{axis}
\end{tikzpicture}
\caption{Idempotent performance on Raw compared to ABP.}
\label{fig:idemraw}
\end{figure}

The above potential explanation for the idempotent queue performance is backed by the fact that the duplicating queue is a lot faster at Raw than the other idempotent queues. This is because the duplicating queue only duplicates work when exactly one thief steals a task at the same time as the owner. In the cases of the other idempotent queues it can happen in many other cases, and therefore occur much more frequently. With less work duplication, the duplicating queue performs a lot better in the Raw case.